{"Perf/learning_time":0.0780332088470459,"Episode/rew_lin_vel_z":-0.7598797678947449,"_timestamp":1.7632953035392785e+09,"Policy/mean_noise_std":0.995688796043396,"_wandb":{"runtime":42},"Episode/rew_orientation":-0.08216815441846848,"Episode/rew_joint_power":-0.004631692543625832,"Episode/rew_foot_clearance":-0.00048763593076728284,"Episode/max_command_x":1,"_runtime":42.140987726,"Train/mean_episode_length":393.296875,"Time/total_timesteps":29600,"Time/eta_s":222756.45144331132,"Console/log":"################################################################################\n                      Learning iteration 36/200000                      \n\n                       Computation: 639 steps/s (collection: 1.174s, learning 0.078s)\n               Value function loss: 0.0267\n                    Surrogate loss: -0.0242\n                   Estimation loss: 0.0725\n                         Swap loss: 0.1025\n             Mean action noise std: 1.00\n                       Mean reward: -12.63\n               Mean episode length: 393.30\n      Mean episode rew_action_rate: -0.2394\n       Mean episode rew_ang_vel_xy: -0.7146\n      Mean episode rew_base_height: -0.0104\n          Mean episode rew_dof_acc: -0.4064\n   Mean episode rew_foot_clearance: -0.0005\n      Mean episode rew_joint_power: -0.0046\n        Mean episode rew_lin_vel_z: -0.7599\n      Mean episode rew_orientation: -0.0822\n       Mean episode rew_smoothness: -0.6908\n Mean episode rew_tracking_ang_vel: 0.0786\n Mean episode rew_tracking_lin_vel: 0.0904\n        Mean episode terrain_level: 0.1250\n        Mean episode max_command_x: 1.0000\n--------------------------------------------------------------------------------\n                   Total timesteps: 29600\n                    Iteration time: 1.25s\n                        Total time: 41.22s\n                               ETA: 222756.5s\n","Episode/terrain_level":0.125,"Episode/rew_base_height":-0.01037090364843607,"Perf/collection_time":1.1737415790557861,"Episode/rew_action_rate":-0.2394174188375473,"Episode/rew_tracking_lin_vel":0.09039872884750366,"Train/mean_reward/time":-12.626004492864013,"Episode/rew_dof_acc":-0.4063647985458374,"Loss/surrogate":-0.02418397683650255,"Perf/total_fps":639,"Time/total_time_s":41.21736264228821,"Loss/learning_rate":1.0000000000000004e-05,"Perf/iteration_time":1.251774787902832,"Train/mean_reward":-12.626004492864013,"_step":36,"iteration":36,"Episode/rew_smoothness":-0.6908477544784546,"Loss/value_function":0.02668570913374424,"Episode/rew_tracking_ang_vel":0.07859648019075394,"Loss/Estimation Loss":0.07253099232912064,"Train/mean_episode_length/time":393.296875,"Loss/Swap Loss":0.10245075076818466,"Episode/rew_ang_vel_xy":-0.7145716547966003}